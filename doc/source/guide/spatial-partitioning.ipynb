{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aca93ab3-f452-4725-b864-b41cd0327954",
   "metadata": {},
   "source": [
    "# Spatial partitioning in Dask-GeoPandas\n",
    "\n",
    "Dask-GeoPandas has implemented `spatial_shuffle` to repartition `Dask.GeoDataFrames`.\n",
    "For those who are not familiar with Dask, a Dask DataFrame is internally split into many partitions, where each partition is a Pandas DataFrame.\n",
    "Partitions are split vertically along the index; \n",
    "\n",
    "<img src=\"https://docs.dask.org/en/latest/_images/dask-dataframe.svg\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "\n",
    "Partitioning a Dask DataFrame avoids element-wise operations, where every possible candidate in a query is evaluated.\n",
    "By evaluating less candidates, we reduce memory overhead and the time taken to execute a query.\n",
    "Common strategies to partition Dask DataFrames include using a fixed number of partitions or partitions based on column values.\n",
    "Dask-GeoPandas partitions GeoDataFrames by taking advantage of their spatial structure.\n",
    "\n",
    "In the rest of this notebook, we use an example dataset to describe how Dask-GeoPandas takes advantage of this spatial structure and some best practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5fbccd-acca-4988-83db-948bf1d2bf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ik19962/.local/lib/python3.8/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.9.1-CAPI-1.14.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import geopandas\n",
    "import dask_geopandas\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6139e44-48d1-4906-b33a-eaa0c9b2bc3b",
   "metadata": {},
   "source": [
    "We first begin by reading USA boundaries from gadm.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d93451-bd17-4ca1-99c1-aed7f4d828b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"https://geodata.ucdavis.edu/gadm/gadm4.0/gpkg/gadm40_USA.gpkg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd57d7c7-91dd-4e09-937b-1707b7b2ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = geopandas.read_file(path, layer=\"ADM_1\")\n",
    "usa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247440da-ada6-4c25-bcd1-e1f0eb221d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and rename cols\n",
    "usa = usa[[\"NAME_1\", \"geometry\"]].rename(columns={\"NAME_1\": \"State\"})\n",
    "usa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cdb8ab-f58c-436b-af5e-919f9f8b41a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313f7bd-9748-4d8c-9e61-8bc112229f3e",
   "metadata": {},
   "source": [
    "We can quickly filter for Contiguous United States, which represents the 48 joining states and the District of Columbia (DC) by the `cx` method.\n",
    "This filters out any geometries using a bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea92949a-7767-4d01-8541-e41ea2f71648",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_cont = usa.cx[-150:-50, 20:50]\n",
    "us_cont.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061cd916-390a-451d-ac46-5e273569c972",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_cont.plot(facecolor=\"none\", linewidth=0.5, edgecolor=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4509aa4-4036-4621-ad0c-2e87eef2340a",
   "metadata": {},
   "source": [
    "We can then transform the `geopandas.GeoDataFrame` to a `dask_geopandas.GeoDataFrame`, with a fixed number of aribitrary partitions - this does not yet spatially partition a Dask GeoDataFrame.\n",
    "Note: we can also read (and export) parquet files in Dask-GeoPandas containing spatially partitioned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd696d3-6492-4890-96c5-8f62b88e3d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_gdf = dask_geopandas.from_geopandas(us_cont, npartitions=4)\n",
    "d_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff72689-2f40-4e43-87c4-a847c9f1bf4a",
   "metadata": {},
   "source": [
    "By visualising the convex hull of each partition, we can get a feel for how the Dask-GeoDataFrame has been partitioned using the fixed number.\n",
    "A useful spatial partitioning scheme is one that minimises the degree of spatial overlap between partitions. \n",
    "By default, the fixed number of partitions does a poor job of spatially partitioning our example data - there is a high degree of overlap between partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5346f4a-cd57-41b2-80a6-f70d11ed5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_gdf.calculate_spatial_partitions() # convex hull\n",
    "d_gdf.spatial_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b09d92-c3cb-4a5d-a453-656336d14a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,6))\n",
    "us_cont.plot(ax=ax)\n",
    "d_gdf.spatial_partitions.plot(ax=ax, cmap=\"tab20\", alpha=0.5)\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04162e01-019a-4419-94ec-aa9687e1bb1a",
   "metadata": {},
   "source": [
    "Spatial partitioning a Dask GeoDataFrames is done using `spatial_shuffle`, which is based on Dasks `set_index` and spatial sorting.\n",
    "\n",
    "## Spatial sorting methods\n",
    "`spatial_shuffle` supports three different partitioning methods, which provide an simple and relatively inexpensive way of representing two-dimensional objects in one-dimensional space.\n",
    "They are called using the `by` parameter;\n",
    "1. Hilbert distance (default)\n",
    "2. Morton distance\n",
    "3. Geohash\n",
    "\n",
    "The first two methods are [space-filling curves](https://en.wikipedia.org/wiki/Space-filling_curve), which are lines that pass through every point in space, in a particular order and pass through points once only, so that each point lies a unique distance along the curve.\n",
    "The range of both curves contain the entire 2-dimensional unit square, which means that the hilbert and morton curve can handle projected coordinates.\n",
    "In general, we recommend the default Hilbert distance because it has better order-preserving behaviour.\n",
    "This is because the curve holds a remarkable mathematical property, where the distance between two consecutive points along the curve is always equal to one.\n",
    "By contrast, the Morton distance or [\"Z-order curve\"](https://en.wikipedia.org/wiki/Z-order_curve) does not hold this property and there are larger \"jumps\" in distances between two consecutive points.\n",
    "Currently, calculated distances along the curves are based on the mid points of geometries.\n",
    "Whilst this is inexpensive, mid points do not represent complex geometries well.\n",
    "Future work will examine various methods for better representating complex geometries.\n",
    "\n",
    "The Geohash, not to be confused with [geohashing](https://geohashing.site/geohashing/Main_Page) is a hierarchical spatial data structure, which subdivides space into buckets of grid shape.\n",
    "Whilst the Geohash does allow binary searchers or spatial indexing, like rtree or quadtree, Geohash is limited to encoding latitude and longitude coordinates.\n",
    "The Geohash can be represented either as text string or integers, where the longer the string/integer is, the more precise the grid shape \n",
    "will be.\n",
    "\n",
    "Below we compare the different sorting methods using the default parameters.\n",
    "All 3 sorting methods reduce the degree of spatial overlap but this stil remains high and could be further improved by controlling specific parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad73df8-8264-4cd8-aa88-185d82ac5305",
   "metadata": {},
   "outputs": [],
   "source": [
    "hilbert = d_gdf.spatial_shuffle(by=\"hilbert\")\n",
    "morton = d_gdf.spatial_shuffle(by=\"morton\")\n",
    "geohash = d_gdf.spatial_shuffle(by=\"geohash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcac318-06de-4144-9d34-b510bddda81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1,ncols=3, figsize=(25,12))\n",
    "ax1, ax2, ax3 = axes.flatten()\n",
    "\n",
    "for ax in axes:\n",
    "    us_cont.plot(ax=ax)\n",
    "\n",
    "hilbert.spatial_partitions.plot(ax=ax1, cmap=\"tab20\", alpha=0.5)\n",
    "morton.spatial_partitions.plot(ax=ax2, cmap=\"tab20\", alpha=0.5)\n",
    "geohash.spatial_partitions.plot(ax=ax3, cmap=\"tab20\", alpha=0.5)\n",
    "\n",
    "[axi.set_axis_off() for axi in axes.ravel()]\n",
    "\n",
    "ax1.set_title(\"Hilbert\", size=16)\n",
    "ax2.set_title(\"Morton\", size=16)\n",
    "ax3.set_title(\"Geohash\", size=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34f773c-0eec-4a78-bc78-66dd6c4ebd22",
   "metadata": {},
   "source": [
    "## npartitions\n",
    "The first parameter is the `npartitions` or number of partitions.\n",
    "The default npartitions is the same number of partitions as the original Dask GeoDataFrame.\n",
    "Whilst increasing the number of partitions will reduce the degree of spatial overlap between partitions, this is also a more expensive operation.\n",
    "Knowing how many partitions to set is tricky because there is no single answer.\n",
    "This depends not only on your data structure but also what you plan to do with your data.\n",
    "Overall, there is a trade off between the up front and geometric operations cost when deciding how to spatially shuffle a Dask GeoDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac66205-25b4-484c-82e0-2bdde227568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit d_gdf.spatial_shuffle(by=\"hilbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f630a4-c282-48bf-b76a-069bb5e16358",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit d_gdf.spatial_shuffle(by=\"hilbert\", npartitions=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4409b1-87f7-4620-9258-c01a0a25bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "hilbert20 = d_gdf.spatial_shuffle(by=\"hilbert\", npartitions=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93531f94-6a4d-4157-aa29-ca6f8cc1f652",
   "metadata": {},
   "source": [
    "Below shows a comparison between the different approaches;\n",
    "1. The original Dask GeoDataFrame with no spatial partitioning\n",
    "2. The same Dask GeoDataFrame spatially shuffled with the default number of partitions as the original Dask GeoDataFrame\n",
    "3. The same Dask GeoDataFrame using 20 partitions.\n",
    "It's quite clear that using 20 partitions does reduce the overall degree of spatial overlap between partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5747f4-3a0f-44b1-811e-1d42c2905331",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1,ncols=3, figsize=(25,12))\n",
    "ax1, ax2, ax3 = axes.flatten()\n",
    "\n",
    "for ax in axes:\n",
    "    us_cont.plot(ax=ax)\n",
    "\n",
    "d_gdf.spatial_partitions.plot(ax=ax1, cmap=\"tab20\", alpha=0.5)\n",
    "hilbert.spatial_partitions.plot(ax=ax2, cmap=\"tab20\", alpha=0.5)\n",
    "hilbert20.spatial_partitions.plot(ax=ax3, cmap=\"tab20\", alpha=0.5)\n",
    "\n",
    "[axi.set_axis_off() for axi in axes.ravel()]\n",
    "\n",
    "ax1.set_title(\"No spatial shuffle, with 4 partitions\", size=16)\n",
    "ax2.set_title(\"Spatial shuffle using default npartitions\", size=16)\n",
    "ax3.set_title(\"Spatial shuffle using 20 partitions\", size=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d25cf2-891d-49b6-9b08-d4ebfabb6ed1",
   "metadata": {},
   "source": [
    "## level\n",
    "The `level` parameter represents the precision of each partitioning method.\n",
    "This defaults to 16 for both the Hilbert and Morton distance.\n",
    "However, the Geohash method does not use this parameter and defaults to the integer representation.\n",
    "We have found there are no significant penalties in selecting the maximum precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a52d9-18a0-4a1c-ba47-90d0186c33d0",
   "metadata": {},
   "source": [
    "## Partitioning guidelines\n",
    "Dask offers some guidance on partitioning Pandas DataFrames, which include;\n",
    "1. If you your DataFrame fit easily into memory, than [Geo]Pandas can often be faster and easier to use than Dask[-GeoPandas] - so we always recommend trying GeoPandas first.\n",
    "2. If you are running into memory and/or performance issues with [Geo]Pandas, then the number of partitions should fit comfortably in memory (each smaller than a gigabyte) - so if you are handling a 10GB dataset, then perhaps try using 10 partitions. \n",
    "3. If you are performing many tasks, where you increase/decrease the size of each DataFrame, it's useful to reconsider how many partitions you need. This may mean repartitioning your DataFrame again or using GeoPandas.\n",
    "4. It may be that only a single component of your workflow does not fit into memory and we recommend using GeoPandas once this single component has been computed.\n",
    "\n",
    "Dask offers [further guidance](https://docs.dask.org/en/latest/best-practices.html) on when/how to use partitioning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
